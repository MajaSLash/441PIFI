{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "This workload is supposed to fetch the feature_engineered, preprocessed, scaled features from each individual person, alongside their gender, emotional state, and unique identifier, in order to train various models, which could also involve hyperparameter tuning based on the initial results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_ready_df = \"../feature_engineering/model_ready.csv\"\n",
    "model_df = pd.read_csv(model_ready_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>person_id</th>\n",
       "      <th>neutral</th>\n",
       "      <th>smile</th>\n",
       "      <th>anger</th>\n",
       "      <th>left_light</th>\n",
       "      <th>EyeLengthRatio</th>\n",
       "      <th>EyeDistanceRatio</th>\n",
       "      <th>NoseRatio</th>\n",
       "      <th>LipSizeRatio</th>\n",
       "      <th>LipLengthRatio</th>\n",
       "      <th>EyeBrowLengthRatio</th>\n",
       "      <th>AggressiveRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953240</td>\n",
       "      <td>-1.874377</td>\n",
       "      <td>0.465741</td>\n",
       "      <td>0.941153</td>\n",
       "      <td>-0.570940</td>\n",
       "      <td>2.860458</td>\n",
       "      <td>-0.249554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.091681</td>\n",
       "      <td>-1.670062</td>\n",
       "      <td>-0.539163</td>\n",
       "      <td>-0.156945</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>1.786591</td>\n",
       "      <td>-0.078427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522945</td>\n",
       "      <td>-1.397896</td>\n",
       "      <td>-0.119616</td>\n",
       "      <td>0.345342</td>\n",
       "      <td>-0.138899</td>\n",
       "      <td>2.419592</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.428806</td>\n",
       "      <td>-0.907017</td>\n",
       "      <td>0.297125</td>\n",
       "      <td>-0.166860</td>\n",
       "      <td>-1.371568</td>\n",
       "      <td>2.683468</td>\n",
       "      <td>-0.556948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>m002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222307</td>\n",
       "      <td>0.665548</td>\n",
       "      <td>-1.172176</td>\n",
       "      <td>-0.262928</td>\n",
       "      <td>-1.070341</td>\n",
       "      <td>0.898074</td>\n",
       "      <td>0.366138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  gender person_id  neutral  smile  anger  left_light  EyeLengthRatio  \\\n",
       "0      0       1      m001        1      0      0           0       -0.953240   \n",
       "1      1       1      m001        0      1      0           0       -0.091681   \n",
       "2      2       1      m001        0      0      1           0        0.522945   \n",
       "3      3       1      m001        0      0      0           1       -1.428806   \n",
       "4      4       1      m002        1      0      0           0       -0.222307   \n",
       "\n",
       "   EyeDistanceRatio  NoseRatio  LipSizeRatio  LipLengthRatio  \\\n",
       "0         -1.874377   0.465741      0.941153       -0.570940   \n",
       "1         -1.670062  -0.539163     -0.156945        0.134949   \n",
       "2         -1.397896  -0.119616      0.345342       -0.138899   \n",
       "3         -0.907017   0.297125     -0.166860       -1.371568   \n",
       "4          0.665548  -1.172176     -0.262928       -1.070341   \n",
       "\n",
       "   EyeBrowLengthRatio  AggressiveRatio  \n",
       "0            2.860458        -0.249554  \n",
       "1            1.786591        -0.078427  \n",
       "2            2.419592         0.009484  \n",
       "3            2.683468        -0.556948  \n",
       "4            0.898074         0.366138  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Because we are dealing with such little data, we have to figure out what exactly to quantify as our training dataset. If we decide to not include person as part of our training, then the model will not be able to identify them correctly at all, so at the bare minimum, at least one emotion from each person should be within the training dataset.\n",
    "\n",
    "I've come to the conclusion that because we are dealing with face identification as our project (that could potentially be deployed for authentication scenarios / context), I believe it is best if the model is overfit to all of the training_data so we can ensure those who should be authenticated are able to, but for new users, the model should automatically reject them. We want this model to work extremely well with our initial 136 persons, but not necsesarily for those who are not part of the original dataset. In addition, we harm our model's performance overall if we decide to split this extremely small dataset into many portions as we will run out of data to effectively train various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>person_id</th>\n",
       "      <th>neutral</th>\n",
       "      <th>smile</th>\n",
       "      <th>anger</th>\n",
       "      <th>left_light</th>\n",
       "      <th>EyeLengthRatio</th>\n",
       "      <th>EyeDistanceRatio</th>\n",
       "      <th>NoseRatio</th>\n",
       "      <th>LipSizeRatio</th>\n",
       "      <th>LipLengthRatio</th>\n",
       "      <th>EyeBrowLengthRatio</th>\n",
       "      <th>AggressiveRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953240</td>\n",
       "      <td>-1.874377</td>\n",
       "      <td>0.465741</td>\n",
       "      <td>0.941153</td>\n",
       "      <td>-0.570940</td>\n",
       "      <td>2.860458</td>\n",
       "      <td>-0.249554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.091681</td>\n",
       "      <td>-1.670062</td>\n",
       "      <td>-0.539163</td>\n",
       "      <td>-0.156945</td>\n",
       "      <td>0.134949</td>\n",
       "      <td>1.786591</td>\n",
       "      <td>-0.078427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522945</td>\n",
       "      <td>-1.397896</td>\n",
       "      <td>-0.119616</td>\n",
       "      <td>0.345342</td>\n",
       "      <td>-0.138899</td>\n",
       "      <td>2.419592</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.428806</td>\n",
       "      <td>-0.907017</td>\n",
       "      <td>0.297125</td>\n",
       "      <td>-0.166860</td>\n",
       "      <td>-1.371568</td>\n",
       "      <td>2.683468</td>\n",
       "      <td>-0.556948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>m002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222307</td>\n",
       "      <td>0.665548</td>\n",
       "      <td>-1.172176</td>\n",
       "      <td>-0.262928</td>\n",
       "      <td>-1.070341</td>\n",
       "      <td>0.898074</td>\n",
       "      <td>0.366138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  gender person_id  neutral  smile  anger  left_light  EyeLengthRatio  \\\n",
       "0      0       1      m001        1      0      0           0       -0.953240   \n",
       "1      1       1      m001        0      1      0           0       -0.091681   \n",
       "2      2       1      m001        0      0      1           0        0.522945   \n",
       "3      3       1      m001        0      0      0           1       -1.428806   \n",
       "4      4       1      m002        1      0      0           0       -0.222307   \n",
       "\n",
       "   EyeDistanceRatio  NoseRatio  LipSizeRatio  LipLengthRatio  \\\n",
       "0         -1.874377   0.465741      0.941153       -0.570940   \n",
       "1         -1.670062  -0.539163     -0.156945        0.134949   \n",
       "2         -1.397896  -0.119616      0.345342       -0.138899   \n",
       "3         -0.907017   0.297125     -0.166860       -1.371568   \n",
       "4          0.665548  -1.172176     -0.262928       -1.070341   \n",
       "\n",
       "   EyeBrowLengthRatio  AggressiveRatio  \n",
       "0            2.860458        -0.249554  \n",
       "1            1.786591        -0.078427  \n",
       "2            2.419592         0.009484  \n",
       "3            2.683468        -0.556948  \n",
       "4            0.898074         0.366138  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out ideal train_test_split (deciding against due to small dataset)\n",
    "X = model_df.drop(['person_id', 'index'],axis=1)\n",
    "y = model_df['person_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Development\n",
    "\n",
    "Parameters are chosen arbitrarily based on previous experience of what usually performed best in other classification scenarios. These parameters will be tuned if the initial models result with a great accuracy score. As this is classification, the cost function / accuracy result is based off of cross-entropy loss as we are dealing with a multinomial classification label problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      1.00      1.00         4\n",
      "        m003       1.00      1.00      1.00         4\n",
      "        m004       1.00      1.00      1.00         4\n",
      "        m005       1.00      1.00      1.00         4\n",
      "        m006       1.00      1.00      1.00         4\n",
      "        m007       1.00      1.00      1.00         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       1.00      1.00      1.00         4\n",
      "        m010       1.00      1.00      1.00         4\n",
      "        m011       1.00      1.00      1.00         4\n",
      "        m012       1.00      1.00      1.00         4\n",
      "        m013       1.00      1.00      1.00         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       1.00      1.00      1.00         4\n",
      "        m016       1.00      1.00      1.00         4\n",
      "        m017       1.00      1.00      1.00         4\n",
      "        m018       1.00      1.00      1.00         4\n",
      "        m019       1.00      1.00      1.00         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      1.00      1.00         4\n",
      "        m022       1.00      1.00      1.00         4\n",
      "        m023       1.00      1.00      1.00         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       1.00      1.00      1.00         4\n",
      "        m026       1.00      1.00      1.00         4\n",
      "        m027       1.00      1.00      1.00         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       1.00      1.00      1.00         4\n",
      "        m030       1.00      1.00      1.00         4\n",
      "        m031       1.00      1.00      1.00         4\n",
      "        m032       1.00      1.00      1.00         4\n",
      "        m033       1.00      1.00      1.00         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       1.00      1.00      1.00         4\n",
      "        m036       1.00      1.00      1.00         4\n",
      "        m037       1.00      1.00      1.00         4\n",
      "        m038       1.00      1.00      1.00         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       1.00      1.00      1.00         4\n",
      "        m041       1.00      1.00      1.00         4\n",
      "        m042       1.00      1.00      1.00         4\n",
      "        m043       1.00      1.00      1.00         4\n",
      "        m044       1.00      1.00      1.00         4\n",
      "        m045       1.00      1.00      1.00         4\n",
      "        m046       1.00      1.00      1.00         4\n",
      "        m047       1.00      1.00      1.00         4\n",
      "        m048       1.00      1.00      1.00         4\n",
      "        m049       1.00      1.00      1.00         4\n",
      "        m050       1.00      1.00      1.00         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       1.00      1.00      1.00         4\n",
      "        m053       1.00      1.00      1.00         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       1.00      1.00      1.00         4\n",
      "        m056       1.00      1.00      1.00         4\n",
      "        m057       1.00      1.00      1.00         4\n",
      "        m058       1.00      1.00      1.00         4\n",
      "        m059       1.00      1.00      1.00         4\n",
      "        m060       1.00      1.00      1.00         4\n",
      "        m061       1.00      1.00      1.00         4\n",
      "        m062       1.00      1.00      1.00         4\n",
      "        m063       1.00      1.00      1.00         4\n",
      "        m064       1.00      1.00      1.00         4\n",
      "        m065       1.00      1.00      1.00         4\n",
      "        m066       1.00      1.00      1.00         4\n",
      "        m067       1.00      1.00      1.00         4\n",
      "        m068       1.00      1.00      1.00         4\n",
      "        m069       1.00      1.00      1.00         4\n",
      "        m070       1.00      1.00      1.00         4\n",
      "        m071       1.00      1.00      1.00         4\n",
      "        m072       1.00      1.00      1.00         4\n",
      "        m073       1.00      1.00      1.00         4\n",
      "        m074       1.00      1.00      1.00         4\n",
      "        m075       1.00      1.00      1.00         4\n",
      "        m076       1.00      1.00      1.00         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       1.00      1.00      1.00         4\n",
      "        w003       1.00      1.00      1.00         4\n",
      "        w004       1.00      1.00      1.00         4\n",
      "        w005       1.00      1.00      1.00         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       1.00      1.00      1.00         4\n",
      "        w009       1.00      1.00      1.00         4\n",
      "        w010       1.00      1.00      1.00         4\n",
      "        w011       1.00      1.00      1.00         4\n",
      "        w012       1.00      1.00      1.00         4\n",
      "        w013       1.00      1.00      1.00         4\n",
      "        w014       1.00      1.00      1.00         4\n",
      "        w015       1.00      1.00      1.00         4\n",
      "        w016       1.00      1.00      1.00         4\n",
      "        w017       1.00      1.00      1.00         4\n",
      "        w018       1.00      1.00      1.00         4\n",
      "        w019       1.00      1.00      1.00         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       1.00      1.00      1.00         4\n",
      "        w022       1.00      1.00      1.00         4\n",
      "        w023       1.00      1.00      1.00         4\n",
      "        w024       1.00      1.00      1.00         4\n",
      "        w025       1.00      1.00      1.00         4\n",
      "        w026       1.00      1.00      1.00         4\n",
      "        w027       1.00      1.00      1.00         4\n",
      "        w028       1.00      1.00      1.00         4\n",
      "        w029       1.00      1.00      1.00         4\n",
      "        w030       1.00      1.00      1.00         4\n",
      "        w031       1.00      1.00      1.00         4\n",
      "        w032       1.00      1.00      1.00         4\n",
      "        w033       1.00      1.00      1.00         4\n",
      "        w034       1.00      1.00      1.00         4\n",
      "        w035       1.00      1.00      1.00         4\n",
      "        w036       1.00      1.00      1.00         4\n",
      "        w037       1.00      1.00      1.00         4\n",
      "        w038       1.00      1.00      1.00         4\n",
      "        w039       1.00      1.00      1.00         4\n",
      "        w040       1.00      1.00      1.00         4\n",
      "        w041       1.00      1.00      1.00         4\n",
      "        w042       1.00      1.00      1.00         4\n",
      "        w043       1.00      1.00      1.00         4\n",
      "        w044       1.00      1.00      1.00         4\n",
      "        w045       1.00      1.00      1.00         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       1.00      1.00      1.00         2\n",
      "        w048       1.00      1.00      1.00         2\n",
      "        w049       1.00      1.00      1.00         2\n",
      "        w050       1.00      1.00      1.00         2\n",
      "        w051       1.00      1.00      1.00         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       1.00      1.00      1.00         2\n",
      "        w056       1.00      1.00      1.00         2\n",
      "        w057       1.00      1.00      1.00         2\n",
      "        w058       1.00      1.00      1.00         2\n",
      "        w059       1.00      1.00      1.00         2\n",
      "        w060       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       509\n",
      "   macro avg       1.00      1.00      1.00       509\n",
      "weighted avg       1.00      1.00      1.00       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn_model.fit(X, y)\n",
    "knn_model.score(X, y)\n",
    "\n",
    "knn_pred = knn_model.predict(X)\n",
    "print(classification_report(y, knn_pred, target_names=knn_model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       0.67      1.00      0.80         4\n",
      "        m002       1.00      0.50      0.67         4\n",
      "        m003       1.00      0.50      0.67         4\n",
      "        m004       0.00      0.00      0.00         4\n",
      "        m005       0.60      0.75      0.67         4\n",
      "        m006       0.40      0.50      0.44         4\n",
      "        m007       1.00      0.25      0.40         4\n",
      "        m008       0.67      1.00      0.80         4\n",
      "        m009       0.00      0.00      0.00         4\n",
      "        m010       0.75      0.75      0.75         4\n",
      "        m011       0.00      0.00      0.00         4\n",
      "        m012       0.40      0.50      0.44         4\n",
      "        m013       1.00      0.75      0.86         4\n",
      "        m014       0.57      1.00      0.73         4\n",
      "        m015       0.50      0.75      0.60         4\n",
      "        m016       1.00      0.50      0.67         4\n",
      "        m017       0.50      0.50      0.50         4\n",
      "        m018       1.00      0.75      0.86         4\n",
      "        m019       0.67      1.00      0.80         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      0.25      0.40         4\n",
      "        m022       0.75      0.75      0.75         4\n",
      "        m023       0.57      1.00      0.73         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       0.60      0.75      0.67         4\n",
      "        m026       0.75      0.75      0.75         4\n",
      "        m027       0.80      1.00      0.89         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       0.60      0.75      0.67         4\n",
      "        m030       0.75      0.75      0.75         4\n",
      "        m031       0.00      0.00      0.00         4\n",
      "        m032       1.00      0.50      0.67         4\n",
      "        m033       0.80      0.80      0.80         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       0.67      0.50      0.57         4\n",
      "        m036       0.00      0.00      0.00         4\n",
      "        m037       0.67      1.00      0.80         4\n",
      "        m038       0.67      0.50      0.57         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       0.60      0.75      0.67         4\n",
      "        m041       1.00      1.00      1.00         4\n",
      "        m042       0.80      1.00      0.89         4\n",
      "        m043       0.40      0.50      0.44         4\n",
      "        m044       0.57      1.00      0.73         4\n",
      "        m045       1.00      0.75      0.86         4\n",
      "        m046       0.75      0.75      0.75         4\n",
      "        m047       1.00      0.75      0.86         4\n",
      "        m048       0.33      0.25      0.29         4\n",
      "        m049       1.00      0.75      0.86         4\n",
      "        m050       0.50      0.75      0.60         4\n",
      "        m051       0.80      1.00      0.89         4\n",
      "        m052       0.00      0.00      0.00         4\n",
      "        m053       0.75      0.75      0.75         4\n",
      "        m054       0.67      1.00      0.80         4\n",
      "        m055       1.00      0.25      0.40         4\n",
      "        m056       0.57      1.00      0.73         4\n",
      "        m057       1.00      0.50      0.67         4\n",
      "        m058       0.60      0.75      0.67         4\n",
      "        m059       0.75      0.75      0.75         4\n",
      "        m060       0.50      0.75      0.60         4\n",
      "        m061       0.67      0.50      0.57         4\n",
      "        m062       0.33      0.25      0.29         4\n",
      "        m063       0.00      0.00      0.00         4\n",
      "        m064       1.00      0.50      0.67         4\n",
      "        m065       0.17      0.25      0.20         4\n",
      "        m066       0.67      1.00      0.80         4\n",
      "        m067       0.67      0.50      0.57         4\n",
      "        m068       0.50      0.75      0.60         4\n",
      "        m069       0.67      1.00      0.80         4\n",
      "        m070       0.67      0.50      0.57         4\n",
      "        m071       0.50      0.50      0.50         4\n",
      "        m072       0.43      0.75      0.55         4\n",
      "        m073       0.60      0.75      0.67         4\n",
      "        m074       0.80      1.00      0.89         4\n",
      "        m075       0.75      0.75      0.75         4\n",
      "        m076       1.00      0.50      0.67         2\n",
      "        w001       0.67      1.00      0.80         4\n",
      "        w002       0.00      0.00      0.00         4\n",
      "        w003       0.50      1.00      0.67         4\n",
      "        w004       0.43      0.75      0.55         4\n",
      "        w005       0.50      0.50      0.50         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       0.50      0.75      0.60         4\n",
      "        w009       0.60      0.75      0.67         4\n",
      "        w010       0.50      0.25      0.33         4\n",
      "        w011       0.57      1.00      0.73         4\n",
      "        w012       0.33      0.50      0.40         4\n",
      "        w013       0.00      0.00      0.00         4\n",
      "        w014       0.50      0.50      0.50         4\n",
      "        w015       0.20      0.25      0.22         4\n",
      "        w016       0.50      0.75      0.60         4\n",
      "        w017       0.50      0.75      0.60         4\n",
      "        w018       0.50      1.00      0.67         4\n",
      "        w019       0.50      0.25      0.33         4\n",
      "        w020       0.80      1.00      0.89         4\n",
      "        w021       0.50      0.25      0.33         4\n",
      "        w022       0.33      0.75      0.46         4\n",
      "        w023       0.00      0.00      0.00         4\n",
      "        w024       0.38      0.75      0.50         4\n",
      "        w025       0.67      0.50      0.57         4\n",
      "        w026       0.67      1.00      0.80         4\n",
      "        w027       0.38      0.75      0.50         4\n",
      "        w028       0.00      0.00      0.00         4\n",
      "        w029       0.60      0.75      0.67         4\n",
      "        w030       0.60      0.75      0.67         4\n",
      "        w031       0.67      0.50      0.57         4\n",
      "        w032       0.67      0.50      0.57         4\n",
      "        w033       0.75      0.75      0.75         4\n",
      "        w034       0.50      0.50      0.50         4\n",
      "        w035       1.00      0.25      0.40         4\n",
      "        w036       0.75      0.75      0.75         4\n",
      "        w037       0.50      0.25      0.33         4\n",
      "        w038       0.80      1.00      0.89         4\n",
      "        w039       0.50      0.50      0.50         4\n",
      "        w040       1.00      0.75      0.86         4\n",
      "        w041       0.44      1.00      0.62         4\n",
      "        w042       0.67      1.00      0.80         4\n",
      "        w043       0.75      0.75      0.75         4\n",
      "        w044       0.50      0.25      0.33         4\n",
      "        w045       0.50      0.25      0.33         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       0.00      0.00      0.00         2\n",
      "        w048       0.00      0.00      0.00         2\n",
      "        w049       0.00      0.00      0.00         2\n",
      "        w050       0.00      0.00      0.00         2\n",
      "        w051       0.00      0.00      0.00         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       0.00      0.00      0.00         2\n",
      "        w056       0.00      0.00      0.00         2\n",
      "        w057       0.00      0.00      0.00         2\n",
      "        w058       0.00      0.00      0.00         2\n",
      "        w059       0.00      0.00      0.00         2\n",
      "        w060       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.62       509\n",
      "   macro avg       0.58      0.60      0.56       509\n",
      "weighted avg       0.60      0.62      0.58       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n",
    "\n",
    "lr_pred = clf.predict(X)\n",
    "print(classification_report(y, lr_pred, target_names=clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      1.00      1.00         4\n",
      "        m003       1.00      1.00      1.00         4\n",
      "        m004       0.80      1.00      0.89         4\n",
      "        m005       1.00      1.00      1.00         4\n",
      "        m006       1.00      1.00      1.00         4\n",
      "        m007       1.00      0.75      0.86         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       1.00      1.00      1.00         4\n",
      "        m010       1.00      1.00      1.00         4\n",
      "        m011       1.00      1.00      1.00         4\n",
      "        m012       1.00      1.00      1.00         4\n",
      "        m013       1.00      1.00      1.00         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       0.80      1.00      0.89         4\n",
      "        m016       1.00      1.00      1.00         4\n",
      "        m017       1.00      1.00      1.00         4\n",
      "        m018       1.00      1.00      1.00         4\n",
      "        m019       1.00      1.00      1.00         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      1.00      1.00         4\n",
      "        m022       1.00      1.00      1.00         4\n",
      "        m023       1.00      1.00      1.00         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       1.00      1.00      1.00         4\n",
      "        m026       1.00      1.00      1.00         4\n",
      "        m027       1.00      1.00      1.00         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       1.00      1.00      1.00         4\n",
      "        m030       1.00      1.00      1.00         4\n",
      "        m031       1.00      1.00      1.00         4\n",
      "        m032       0.67      1.00      0.80         4\n",
      "        m033       1.00      1.00      1.00         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       1.00      1.00      1.00         4\n",
      "        m036       1.00      1.00      1.00         4\n",
      "        m037       1.00      1.00      1.00         4\n",
      "        m038       1.00      1.00      1.00         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       1.00      1.00      1.00         4\n",
      "        m041       1.00      1.00      1.00         4\n",
      "        m042       1.00      1.00      1.00         4\n",
      "        m043       1.00      1.00      1.00         4\n",
      "        m044       1.00      1.00      1.00         4\n",
      "        m045       1.00      1.00      1.00         4\n",
      "        m046       1.00      1.00      1.00         4\n",
      "        m047       1.00      1.00      1.00         4\n",
      "        m048       0.80      1.00      0.89         4\n",
      "        m049       1.00      1.00      1.00         4\n",
      "        m050       1.00      1.00      1.00         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       1.00      1.00      1.00         4\n",
      "        m053       1.00      1.00      1.00         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       1.00      1.00      1.00         4\n",
      "        m056       1.00      1.00      1.00         4\n",
      "        m057       1.00      1.00      1.00         4\n",
      "        m058       1.00      1.00      1.00         4\n",
      "        m059       1.00      0.75      0.86         4\n",
      "        m060       1.00      1.00      1.00         4\n",
      "        m061       1.00      1.00      1.00         4\n",
      "        m062       1.00      1.00      1.00         4\n",
      "        m063       1.00      1.00      1.00         4\n",
      "        m064       1.00      0.50      0.67         4\n",
      "        m065       1.00      0.75      0.86         4\n",
      "        m066       1.00      1.00      1.00         4\n",
      "        m067       1.00      1.00      1.00         4\n",
      "        m068       1.00      1.00      1.00         4\n",
      "        m069       1.00      1.00      1.00         4\n",
      "        m070       1.00      1.00      1.00         4\n",
      "        m071       1.00      1.00      1.00         4\n",
      "        m072       1.00      1.00      1.00         4\n",
      "        m073       1.00      1.00      1.00         4\n",
      "        m074       1.00      1.00      1.00         4\n",
      "        m075       1.00      1.00      1.00         4\n",
      "        m076       1.00      1.00      1.00         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       1.00      0.75      0.86         4\n",
      "        w003       1.00      1.00      1.00         4\n",
      "        w004       1.00      1.00      1.00         4\n",
      "        w005       1.00      1.00      1.00         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       1.00      1.00      1.00         4\n",
      "        w009       1.00      1.00      1.00         4\n",
      "        w010       1.00      1.00      1.00         4\n",
      "        w011       1.00      1.00      1.00         4\n",
      "        w012       1.00      1.00      1.00         4\n",
      "        w013       1.00      1.00      1.00         4\n",
      "        w014       1.00      1.00      1.00         4\n",
      "        w015       1.00      1.00      1.00         4\n",
      "        w016       1.00      1.00      1.00         4\n",
      "        w017       1.00      1.00      1.00         4\n",
      "        w018       1.00      1.00      1.00         4\n",
      "        w019       1.00      1.00      1.00         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       1.00      1.00      1.00         4\n",
      "        w022       1.00      1.00      1.00         4\n",
      "        w023       1.00      1.00      1.00         4\n",
      "        w024       1.00      1.00      1.00         4\n",
      "        w025       1.00      1.00      1.00         4\n",
      "        w026       1.00      1.00      1.00         4\n",
      "        w027       1.00      1.00      1.00         4\n",
      "        w028       1.00      1.00      1.00         4\n",
      "        w029       1.00      1.00      1.00         4\n",
      "        w030       1.00      1.00      1.00         4\n",
      "        w031       1.00      1.00      1.00         4\n",
      "        w032       1.00      1.00      1.00         4\n",
      "        w033       1.00      1.00      1.00         4\n",
      "        w034       1.00      1.00      1.00         4\n",
      "        w035       1.00      1.00      1.00         4\n",
      "        w036       1.00      1.00      1.00         4\n",
      "        w037       1.00      1.00      1.00         4\n",
      "        w038       1.00      1.00      1.00         4\n",
      "        w039       1.00      1.00      1.00         4\n",
      "        w040       1.00      1.00      1.00         4\n",
      "        w041       1.00      1.00      1.00         4\n",
      "        w042       1.00      1.00      1.00         4\n",
      "        w043       1.00      1.00      1.00         4\n",
      "        w044       0.80      1.00      0.89         4\n",
      "        w045       1.00      1.00      1.00         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       1.00      1.00      1.00         2\n",
      "        w048       1.00      1.00      1.00         2\n",
      "        w049       1.00      1.00      1.00         2\n",
      "        w050       1.00      1.00      1.00         2\n",
      "        w051       1.00      1.00      1.00         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       1.00      1.00      1.00         2\n",
      "        w056       1.00      1.00      1.00         2\n",
      "        w057       1.00      1.00      1.00         2\n",
      "        w058       1.00      1.00      1.00         2\n",
      "        w059       1.00      1.00      1.00         2\n",
      "        w060       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.99       509\n",
      "   macro avg       0.99      0.99      0.99       509\n",
      "weighted avg       0.99      0.99      0.99       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "m_clf = MLPClassifier(random_state=1, max_iter=300).fit(X, y)\n",
    "m_clf.score(X, y)\n",
    "\n",
    "m_pred = m_clf.predict(X)\n",
    "print(classification_report(y, m_pred, target_names=m_clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593320235756385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      0.75      0.86         4\n",
      "        m003       0.40      0.50      0.44         4\n",
      "        m004       1.00      0.50      0.67         4\n",
      "        m005       1.00      0.50      0.67         4\n",
      "        m006       1.00      0.25      0.40         4\n",
      "        m007       1.00      0.25      0.40         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       0.33      0.25      0.29         4\n",
      "        m010       0.75      0.75      0.75         4\n",
      "        m011       0.20      0.25      0.22         4\n",
      "        m012       1.00      0.50      0.67         4\n",
      "        m013       0.67      0.50      0.57         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       1.00      0.75      0.86         4\n",
      "        m016       0.67      0.50      0.57         4\n",
      "        m017       1.00      0.25      0.40         4\n",
      "        m018       1.00      0.75      0.86         4\n",
      "        m019       0.67      0.50      0.57         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       0.67      0.50      0.57         4\n",
      "        m022       0.75      0.75      0.75         4\n",
      "        m023       1.00      1.00      1.00         4\n",
      "        m024       1.00      0.50      0.67         4\n",
      "        m025       1.00      0.75      0.86         4\n",
      "        m026       1.00      0.75      0.86         4\n",
      "        m027       0.80      1.00      0.89         4\n",
      "        m028       0.80      1.00      0.89         4\n",
      "        m029       1.00      1.00      1.00         4\n",
      "        m030       0.75      0.75      0.75         4\n",
      "        m031       1.00      0.50      0.67         4\n",
      "        m032       0.67      0.50      0.57         4\n",
      "        m033       1.00      0.60      0.75         5\n",
      "        m034       0.50      1.00      0.67         2\n",
      "        m035       0.50      0.50      0.50         4\n",
      "        m036       1.00      0.75      0.86         4\n",
      "        m037       1.00      0.75      0.86         4\n",
      "        m038       1.00      0.75      0.86         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       1.00      0.75      0.86         4\n",
      "        m041       1.00      0.75      0.86         4\n",
      "        m042       1.00      0.75      0.86         4\n",
      "        m043       1.00      0.75      0.86         4\n",
      "        m044       0.80      1.00      0.89         4\n",
      "        m045       1.00      0.50      0.67         4\n",
      "        m046       1.00      0.75      0.86         4\n",
      "        m047       0.80      1.00      0.89         4\n",
      "        m048       0.50      0.50      0.50         4\n",
      "        m049       1.00      0.50      0.67         4\n",
      "        m050       1.00      0.75      0.86         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       0.50      0.25      0.33         4\n",
      "        m053       0.67      1.00      0.80         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       0.67      0.50      0.57         4\n",
      "        m056       1.00      0.50      0.67         4\n",
      "        m057       0.43      0.75      0.55         4\n",
      "        m058       1.00      0.75      0.86         4\n",
      "        m059       0.75      0.75      0.75         4\n",
      "        m060       0.50      0.25      0.33         4\n",
      "        m061       1.00      0.50      0.67         4\n",
      "        m062       0.33      0.50      0.40         4\n",
      "        m063       0.50      0.50      0.50         4\n",
      "        m064       0.33      0.25      0.29         4\n",
      "        m065       0.50      0.50      0.50         4\n",
      "        m066       0.33      0.25      0.29         4\n",
      "        m067       0.43      0.75      0.55         4\n",
      "        m068       0.00      0.00      0.00         4\n",
      "        m069       0.33      0.25      0.29         4\n",
      "        m070       1.00      0.50      0.67         4\n",
      "        m071       1.00      0.50      0.67         4\n",
      "        m072       0.67      0.50      0.57         4\n",
      "        m073       1.00      1.00      1.00         4\n",
      "        m074       0.75      0.75      0.75         4\n",
      "        m075       0.75      0.75      0.75         4\n",
      "        m076       0.04      1.00      0.08         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       0.50      0.25      0.33         4\n",
      "        w003       1.00      0.25      0.40         4\n",
      "        w004       0.50      0.25      0.33         4\n",
      "        w005       1.00      0.50      0.67         4\n",
      "        w007       1.00      0.75      0.86         4\n",
      "        w008       1.00      1.00      1.00         4\n",
      "        w009       0.67      0.50      0.57         4\n",
      "        w010       1.00      0.25      0.40         4\n",
      "        w011       0.50      0.50      0.50         4\n",
      "        w012       0.00      0.00      0.00         4\n",
      "        w013       0.00      0.00      0.00         4\n",
      "        w014       0.50      0.25      0.33         4\n",
      "        w015       1.00      0.50      0.67         4\n",
      "        w016       1.00      0.25      0.40         4\n",
      "        w017       0.50      0.25      0.33         4\n",
      "        w018       1.00      0.50      0.67         4\n",
      "        w019       0.40      0.50      0.44         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       1.00      0.25      0.40         4\n",
      "        w022       1.00      0.25      0.40         4\n",
      "        w023       0.75      0.75      0.75         4\n",
      "        w024       0.50      0.25      0.33         4\n",
      "        w025       0.67      0.50      0.57         4\n",
      "        w026       1.00      0.25      0.40         4\n",
      "        w027       1.00      0.50      0.67         4\n",
      "        w028       0.75      0.75      0.75         4\n",
      "        w029       1.00      0.75      0.86         4\n",
      "        w030       1.00      1.00      1.00         4\n",
      "        w031       0.25      0.25      0.25         4\n",
      "        w032       0.00      0.00      0.00         4\n",
      "        w033       0.67      0.50      0.57         4\n",
      "        w034       1.00      0.50      0.67         4\n",
      "        w035       1.00      0.25      0.40         4\n",
      "        w036       1.00      0.25      0.40         4\n",
      "        w037       0.60      0.75      0.67         4\n",
      "        w038       1.00      0.50      0.67         4\n",
      "        w039       1.00      0.50      0.67         4\n",
      "        w040       0.67      0.50      0.57         4\n",
      "        w041       0.67      0.50      0.57         4\n",
      "        w042       1.00      0.50      0.67         4\n",
      "        w043       0.67      0.50      0.57         4\n",
      "        w044       0.50      0.25      0.33         4\n",
      "        w045       0.33      0.25      0.29         4\n",
      "        w046       1.00      0.50      0.67         4\n",
      "        w047       0.33      1.00      0.50         2\n",
      "        w048       1.00      1.00      1.00         2\n",
      "        w049       1.00      1.00      1.00         2\n",
      "        w050       0.25      1.00      0.40         2\n",
      "        w051       0.04      0.50      0.07         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       1.00      1.00      1.00         2\n",
      "        w056       0.20      1.00      0.33         2\n",
      "        w057       0.33      1.00      0.50         2\n",
      "        w058       0.67      1.00      0.80         2\n",
      "        w059       0.09      1.00      0.16         2\n",
      "        w060       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.59       509\n",
      "   macro avg       0.75      0.62      0.63       509\n",
      "weighted avg       0.77      0.59      0.63       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X, y)\n",
    "print(nb.score(X, y))\n",
    "\n",
    "nb_pred = nb.predict(X)\n",
    "print(classification_report(y, nb_pred, target_names=nb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6090373280943026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       0.80      1.00      0.89         4\n",
      "        m003       0.60      0.75      0.67         4\n",
      "        m004       1.00      0.25      0.40         4\n",
      "        m005       1.00      0.50      0.67         4\n",
      "        m006       0.50      1.00      0.67         4\n",
      "        m007       0.75      0.75      0.75         4\n",
      "        m008       0.80      1.00      0.89         4\n",
      "        m009       0.00      0.00      0.00         4\n",
      "        m010       0.50      0.75      0.60         4\n",
      "        m011       0.00      0.00      0.00         4\n",
      "        m012       0.50      0.75      0.60         4\n",
      "        m013       1.00      0.50      0.67         4\n",
      "        m014       1.00      0.75      0.86         4\n",
      "        m015       0.50      0.75      0.60         4\n",
      "        m016       0.75      0.75      0.75         4\n",
      "        m017       1.00      0.75      0.86         4\n",
      "        m018       1.00      0.75      0.86         4\n",
      "        m019       1.00      0.50      0.67         4\n",
      "        m020       1.00      0.75      0.86         4\n",
      "        m021       1.00      0.25      0.40         4\n",
      "        m022       0.60      0.75      0.67         4\n",
      "        m023       0.67      1.00      0.80         4\n",
      "        m024       0.75      0.75      0.75         4\n",
      "        m025       0.75      0.75      0.75         4\n",
      "        m026       0.50      0.50      0.50         4\n",
      "        m027       0.60      0.75      0.67         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       0.33      0.75      0.46         4\n",
      "        m030       0.67      0.50      0.57         4\n",
      "        m031       0.17      0.25      0.20         4\n",
      "        m032       0.60      0.75      0.67         4\n",
      "        m033       0.80      0.80      0.80         5\n",
      "        m034       0.00      0.00      0.00         2\n",
      "        m035       0.67      0.50      0.57         4\n",
      "        m036       1.00      0.25      0.40         4\n",
      "        m037       0.60      0.75      0.67         4\n",
      "        m038       0.33      0.25      0.29         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       0.75      0.75      0.75         4\n",
      "        m041       0.75      0.75      0.75         4\n",
      "        m042       1.00      1.00      1.00         4\n",
      "        m043       1.00      0.50      0.67         4\n",
      "        m044       0.67      1.00      0.80         4\n",
      "        m045       0.67      0.50      0.57         4\n",
      "        m046       1.00      0.50      0.67         4\n",
      "        m047       1.00      1.00      1.00         4\n",
      "        m048       0.00      0.00      0.00         4\n",
      "        m049       1.00      0.50      0.67         4\n",
      "        m050       0.25      0.25      0.25         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       0.33      0.25      0.29         4\n",
      "        m053       0.80      1.00      0.89         4\n",
      "        m054       0.80      1.00      0.89         4\n",
      "        m055       0.33      0.25      0.29         4\n",
      "        m056       1.00      1.00      1.00         4\n",
      "        m057       0.40      0.50      0.44         4\n",
      "        m058       0.60      0.75      0.67         4\n",
      "        m059       1.00      0.75      0.86         4\n",
      "        m060       0.50      0.75      0.60         4\n",
      "        m061       1.00      0.75      0.86         4\n",
      "        m062       0.08      0.25      0.12         4\n",
      "        m063       0.67      0.50      0.57         4\n",
      "        m064       1.00      0.25      0.40         4\n",
      "        m065       1.00      0.25      0.40         4\n",
      "        m066       1.00      0.75      0.86         4\n",
      "        m067       0.40      0.50      0.44         4\n",
      "        m068       0.43      0.75      0.55         4\n",
      "        m069       0.30      0.75      0.43         4\n",
      "        m070       0.38      0.75      0.50         4\n",
      "        m071       0.50      0.75      0.60         4\n",
      "        m072       0.43      0.75      0.55         4\n",
      "        m073       0.43      0.75      0.55         4\n",
      "        m074       0.75      0.75      0.75         4\n",
      "        m075       1.00      0.75      0.86         4\n",
      "        m076       0.00      0.00      0.00         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       0.50      0.50      0.50         4\n",
      "        w003       0.50      1.00      0.67         4\n",
      "        w004       0.43      0.75      0.55         4\n",
      "        w005       0.38      0.75      0.50         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       1.00      0.75      0.86         4\n",
      "        w009       0.50      0.50      0.50         4\n",
      "        w010       0.67      0.50      0.57         4\n",
      "        w011       1.00      0.75      0.86         4\n",
      "        w012       0.67      0.50      0.57         4\n",
      "        w013       0.20      0.25      0.22         4\n",
      "        w014       0.75      0.75      0.75         4\n",
      "        w015       0.25      0.50      0.33         4\n",
      "        w016       0.75      0.75      0.75         4\n",
      "        w017       0.75      0.75      0.75         4\n",
      "        w018       0.50      0.75      0.60         4\n",
      "        w019       0.22      0.50      0.31         4\n",
      "        w020       0.80      1.00      0.89         4\n",
      "        w021       0.00      0.00      0.00         4\n",
      "        w022       0.75      0.75      0.75         4\n",
      "        w023       0.40      0.50      0.44         4\n",
      "        w024       0.40      0.50      0.44         4\n",
      "        w025       0.25      0.25      0.25         4\n",
      "        w026       0.80      1.00      0.89         4\n",
      "        w027       0.44      1.00      0.62         4\n",
      "        w028       0.60      0.75      0.67         4\n",
      "        w029       0.60      0.75      0.67         4\n",
      "        w030       0.80      1.00      0.89         4\n",
      "        w031       0.50      0.50      0.50         4\n",
      "        w032       0.33      0.25      0.29         4\n",
      "        w033       1.00      0.75      0.86         4\n",
      "        w034       0.75      0.75      0.75         4\n",
      "        w035       1.00      0.25      0.40         4\n",
      "        w036       0.75      0.75      0.75         4\n",
      "        w037       1.00      0.75      0.86         4\n",
      "        w038       0.75      0.75      0.75         4\n",
      "        w039       0.33      0.50      0.40         4\n",
      "        w040       0.60      0.75      0.67         4\n",
      "        w041       0.50      0.50      0.50         4\n",
      "        w042       0.57      1.00      0.73         4\n",
      "        w043       1.00      0.50      0.67         4\n",
      "        w044       1.00      0.25      0.40         4\n",
      "        w045       0.00      0.00      0.00         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       0.00      0.00      0.00         2\n",
      "        w048       0.00      0.00      0.00         2\n",
      "        w049       0.00      0.00      0.00         2\n",
      "        w050       0.00      0.00      0.00         2\n",
      "        w051       0.00      0.00      0.00         2\n",
      "        w052       1.00      0.50      0.67         2\n",
      "        w053       0.00      0.00      0.00         2\n",
      "        w054       0.00      0.00      0.00         2\n",
      "        w055       0.00      0.00      0.00         2\n",
      "        w056       0.00      0.00      0.00         2\n",
      "        w057       0.00      0.00      0.00         2\n",
      "        w058       0.00      0.00      0.00         2\n",
      "        w059       0.00      0.00      0.00         2\n",
      "        w060       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.61       509\n",
      "   macro avg       0.59      0.57      0.55       509\n",
      "weighted avg       0.63      0.61      0.59       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\techg\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X, y)\n",
    "print(svm_clf.score(X, y))\n",
    "\n",
    "svm_pred = svm_clf.predict(X)\n",
    "print(classification_report(y, svm_pred, target_names=svm_clf.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "\n",
      "Best estimator:\n",
      "MLPClassifier(alpha=0.001, hidden_layer_sizes=(100, 100), max_iter=300,\n",
      "              random_state=1)\n",
      "\n",
      "Best accuracy score:\n",
      "0.18856015779092705\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      1.00      1.00         4\n",
      "        m003       1.00      1.00      1.00         4\n",
      "        m004       1.00      1.00      1.00         4\n",
      "        m005       1.00      1.00      1.00         4\n",
      "        m006       1.00      1.00      1.00         4\n",
      "        m007       1.00      1.00      1.00         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       1.00      1.00      1.00         4\n",
      "        m010       1.00      1.00      1.00         4\n",
      "        m011       1.00      1.00      1.00         4\n",
      "        m012       1.00      1.00      1.00         4\n",
      "        m013       1.00      1.00      1.00         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       1.00      1.00      1.00         4\n",
      "        m016       1.00      1.00      1.00         4\n",
      "        m017       1.00      1.00      1.00         4\n",
      "        m018       1.00      1.00      1.00         4\n",
      "        m019       1.00      1.00      1.00         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      1.00      1.00         4\n",
      "        m022       1.00      1.00      1.00         4\n",
      "        m023       1.00      1.00      1.00         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       1.00      1.00      1.00         4\n",
      "        m026       1.00      1.00      1.00         4\n",
      "        m027       1.00      1.00      1.00         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       1.00      1.00      1.00         4\n",
      "        m030       1.00      1.00      1.00         4\n",
      "        m031       1.00      1.00      1.00         4\n",
      "        m032       1.00      1.00      1.00         4\n",
      "        m033       1.00      1.00      1.00         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       1.00      1.00      1.00         4\n",
      "        m036       1.00      1.00      1.00         4\n",
      "        m037       1.00      1.00      1.00         4\n",
      "        m038       1.00      1.00      1.00         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       1.00      1.00      1.00         4\n",
      "        m041       1.00      1.00      1.00         4\n",
      "        m042       1.00      1.00      1.00         4\n",
      "        m043       1.00      1.00      1.00         4\n",
      "        m044       1.00      1.00      1.00         4\n",
      "        m045       1.00      1.00      1.00         4\n",
      "        m046       1.00      1.00      1.00         4\n",
      "        m047       1.00      1.00      1.00         4\n",
      "        m048       1.00      1.00      1.00         4\n",
      "        m049       1.00      1.00      1.00         4\n",
      "        m050       1.00      1.00      1.00         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       1.00      1.00      1.00         4\n",
      "        m053       1.00      1.00      1.00         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       1.00      1.00      1.00         4\n",
      "        m056       1.00      1.00      1.00         4\n",
      "        m057       1.00      1.00      1.00         4\n",
      "        m058       1.00      1.00      1.00         4\n",
      "        m059       1.00      1.00      1.00         4\n",
      "        m060       1.00      1.00      1.00         4\n",
      "        m061       1.00      1.00      1.00         4\n",
      "        m062       1.00      1.00      1.00         4\n",
      "        m063       1.00      1.00      1.00         4\n",
      "        m064       1.00      1.00      1.00         4\n",
      "        m065       1.00      1.00      1.00         4\n",
      "        m066       1.00      1.00      1.00         4\n",
      "        m067       1.00      1.00      1.00         4\n",
      "        m068       1.00      1.00      1.00         4\n",
      "        m069       1.00      1.00      1.00         4\n",
      "        m070       1.00      1.00      1.00         4\n",
      "        m071       1.00      1.00      1.00         4\n",
      "        m072       1.00      1.00      1.00         4\n",
      "        m073       1.00      1.00      1.00         4\n",
      "        m074       1.00      1.00      1.00         4\n",
      "        m075       1.00      1.00      1.00         4\n",
      "        m076       1.00      1.00      1.00         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       1.00      1.00      1.00         4\n",
      "        w003       1.00      1.00      1.00         4\n",
      "        w004       1.00      1.00      1.00         4\n",
      "        w005       1.00      1.00      1.00         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       1.00      1.00      1.00         4\n",
      "        w009       1.00      1.00      1.00         4\n",
      "        w010       1.00      1.00      1.00         4\n",
      "        w011       1.00      1.00      1.00         4\n",
      "        w012       1.00      1.00      1.00         4\n",
      "        w013       1.00      1.00      1.00         4\n",
      "        w014       1.00      1.00      1.00         4\n",
      "        w015       1.00      1.00      1.00         4\n",
      "        w016       1.00      1.00      1.00         4\n",
      "        w017       1.00      1.00      1.00         4\n",
      "        w018       1.00      1.00      1.00         4\n",
      "        w019       1.00      1.00      1.00         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       1.00      1.00      1.00         4\n",
      "        w022       1.00      1.00      1.00         4\n",
      "        w023       1.00      1.00      1.00         4\n",
      "        w024       1.00      1.00      1.00         4\n",
      "        w025       1.00      1.00      1.00         4\n",
      "        w026       1.00      1.00      1.00         4\n",
      "        w027       1.00      1.00      1.00         4\n",
      "        w028       1.00      1.00      1.00         4\n",
      "        w029       1.00      1.00      1.00         4\n",
      "        w030       1.00      1.00      1.00         4\n",
      "        w031       1.00      1.00      1.00         4\n",
      "        w032       1.00      1.00      1.00         4\n",
      "        w033       1.00      1.00      1.00         4\n",
      "        w034       1.00      1.00      1.00         4\n",
      "        w035       1.00      1.00      1.00         4\n",
      "        w036       1.00      1.00      1.00         4\n",
      "        w037       1.00      1.00      1.00         4\n",
      "        w038       1.00      1.00      1.00         4\n",
      "        w039       1.00      1.00      1.00         4\n",
      "        w040       1.00      1.00      1.00         4\n",
      "        w041       1.00      1.00      1.00         4\n",
      "        w042       1.00      1.00      1.00         4\n",
      "        w043       1.00      1.00      1.00         4\n",
      "        w044       1.00      1.00      1.00         4\n",
      "        w045       1.00      1.00      1.00         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       1.00      1.00      1.00         2\n",
      "        w048       1.00      1.00      1.00         2\n",
      "        w049       1.00      1.00      1.00         2\n",
      "        w050       1.00      1.00      1.00         2\n",
      "        w051       1.00      1.00      1.00         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       1.00      1.00      1.00         2\n",
      "        w056       1.00      1.00      1.00         2\n",
      "        w057       1.00      1.00      1.00         2\n",
      "        w058       1.00      1.00      1.00         2\n",
      "        w059       1.00      1.00      1.00         2\n",
      "        w060       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       509\n",
      "   macro avg       1.00      1.00      1.00       509\n",
      "weighted avg       1.00      1.00      1.00       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Create MLPClassifier\n",
    "m_clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=m_clf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print the best estimator found\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"\\nBest estimator:\")\n",
    "print(best_estimator)\n",
    "\n",
    "# Print the best score found\n",
    "print(\"\\nBest accuracy score:\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Get predictions using the best estimator\n",
    "m_pred = best_estimator.predict(X)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, m_pred, target_names=best_estimator.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best estimator:\n",
      "LogisticRegression(C=10, max_iter=300, random_state=1, solver='liblinear')\n",
      "\n",
      "Best accuracy score:\n",
      "0.17688827010093977\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      1.00      1.00         4\n",
      "        m003       1.00      0.25      0.40         4\n",
      "        m004       0.40      0.50      0.44         4\n",
      "        m005       1.00      1.00      1.00         4\n",
      "        m006       0.33      0.50      0.40         4\n",
      "        m007       0.50      0.50      0.50         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       0.50      0.25      0.33         4\n",
      "        m010       0.75      0.75      0.75         4\n",
      "        m011       1.00      0.25      0.40         4\n",
      "        m012       0.67      0.50      0.57         4\n",
      "        m013       1.00      0.75      0.86         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       0.57      1.00      0.73         4\n",
      "        m016       1.00      0.50      0.67         4\n",
      "        m017       1.00      1.00      1.00         4\n",
      "        m018       0.75      0.75      0.75         4\n",
      "        m019       1.00      1.00      1.00         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      0.25      0.40         4\n",
      "        m022       0.43      0.75      0.55         4\n",
      "        m023       0.80      1.00      0.89         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       0.75      0.75      0.75         4\n",
      "        m026       1.00      0.75      0.86         4\n",
      "        m027       1.00      1.00      1.00         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       0.80      1.00      0.89         4\n",
      "        m030       1.00      0.75      0.86         4\n",
      "        m031       0.50      0.50      0.50         4\n",
      "        m032       0.75      0.75      0.75         4\n",
      "        m033       0.80      0.80      0.80         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       1.00      0.75      0.86         4\n",
      "        m036       0.00      0.00      0.00         4\n",
      "        m037       0.80      1.00      0.89         4\n",
      "        m038       0.60      0.75      0.67         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       0.50      0.25      0.33         4\n",
      "        m041       0.67      1.00      0.80         4\n",
      "        m042       0.75      0.75      0.75         4\n",
      "        m043       0.75      0.75      0.75         4\n",
      "        m044       0.67      1.00      0.80         4\n",
      "        m045       1.00      1.00      1.00         4\n",
      "        m046       0.50      0.75      0.60         4\n",
      "        m047       0.50      0.75      0.60         4\n",
      "        m048       0.60      0.75      0.67         4\n",
      "        m049       0.60      0.75      0.67         4\n",
      "        m050       1.00      0.75      0.86         4\n",
      "        m051       0.75      0.75      0.75         4\n",
      "        m052       0.50      0.25      0.33         4\n",
      "        m053       0.60      0.75      0.67         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       1.00      0.75      0.86         4\n",
      "        m056       0.75      0.75      0.75         4\n",
      "        m057       0.50      0.75      0.60         4\n",
      "        m058       0.60      0.75      0.67         4\n",
      "        m059       1.00      0.50      0.67         4\n",
      "        m060       0.75      0.75      0.75         4\n",
      "        m061       1.00      0.75      0.86         4\n",
      "        m062       0.50      0.50      0.50         4\n",
      "        m063       0.67      0.50      0.57         4\n",
      "        m064       0.00      0.00      0.00         4\n",
      "        m065       0.67      0.50      0.57         4\n",
      "        m066       0.57      1.00      0.73         4\n",
      "        m067       0.50      0.25      0.33         4\n",
      "        m068       0.50      0.75      0.60         4\n",
      "        m069       0.67      1.00      0.80         4\n",
      "        m070       0.50      0.50      0.50         4\n",
      "        m071       0.50      0.50      0.50         4\n",
      "        m072       0.33      0.50      0.40         4\n",
      "        m073       0.67      1.00      0.80         4\n",
      "        m074       0.80      1.00      0.89         4\n",
      "        m075       1.00      0.50      0.67         4\n",
      "        m076       1.00      1.00      1.00         2\n",
      "        w001       0.80      1.00      0.89         4\n",
      "        w002       0.00      0.00      0.00         4\n",
      "        w003       0.80      1.00      0.89         4\n",
      "        w004       0.60      0.75      0.67         4\n",
      "        w005       1.00      1.00      1.00         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       0.60      0.75      0.67         4\n",
      "        w009       1.00      1.00      1.00         4\n",
      "        w010       0.50      0.25      0.33         4\n",
      "        w011       0.57      1.00      0.73         4\n",
      "        w012       0.43      0.75      0.55         4\n",
      "        w013       1.00      0.25      0.40         4\n",
      "        w014       0.67      0.50      0.57         4\n",
      "        w015       0.50      1.00      0.67         4\n",
      "        w016       1.00      0.75      0.86         4\n",
      "        w017       0.75      0.75      0.75         4\n",
      "        w018       0.67      1.00      0.80         4\n",
      "        w019       0.67      0.50      0.57         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       0.50      0.25      0.33         4\n",
      "        w022       0.43      0.75      0.55         4\n",
      "        w023       0.50      0.25      0.33         4\n",
      "        w024       0.75      0.75      0.75         4\n",
      "        w025       0.50      0.25      0.33         4\n",
      "        w026       1.00      1.00      1.00         4\n",
      "        w027       0.38      0.75      0.50         4\n",
      "        w028       0.00      0.00      0.00         4\n",
      "        w029       0.75      0.75      0.75         4\n",
      "        w030       0.67      1.00      0.80         4\n",
      "        w031       0.67      0.50      0.57         4\n",
      "        w032       0.67      1.00      0.80         4\n",
      "        w033       0.80      1.00      0.89         4\n",
      "        w034       0.75      0.75      0.75         4\n",
      "        w035       1.00      0.25      0.40         4\n",
      "        w036       0.80      1.00      0.89         4\n",
      "        w037       0.67      0.50      0.57         4\n",
      "        w038       0.80      1.00      0.89         4\n",
      "        w039       0.20      0.25      0.22         4\n",
      "        w040       1.00      1.00      1.00         4\n",
      "        w041       0.80      1.00      0.89         4\n",
      "        w042       0.67      1.00      0.80         4\n",
      "        w043       1.00      0.75      0.86         4\n",
      "        w044       0.40      0.50      0.44         4\n",
      "        w045       1.00      0.50      0.67         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       1.00      1.00      1.00         2\n",
      "        w048       0.00      0.00      0.00         2\n",
      "        w049       0.00      0.00      0.00         2\n",
      "        w050       0.00      0.00      0.00         2\n",
      "        w051       0.50      0.50      0.50         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       0.67      1.00      0.80         2\n",
      "        w055       0.50      0.50      0.50         2\n",
      "        w056       0.50      0.50      0.50         2\n",
      "        w057       0.00      0.00      0.00         2\n",
      "        w058       1.00      0.50      0.67         2\n",
      "        w059       1.00      0.50      0.67         2\n",
      "        w060       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.71       509\n",
      "   macro avg       0.71      0.70      0.68       509\n",
      "weighted avg       0.72      0.71      0.69       509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "}\n",
    "\n",
    "# Create LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state=1, max_iter=300)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lr_clf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print the best estimator found\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"\\nBest estimator:\")\n",
    "print(best_estimator)\n",
    "\n",
    "# Print the best score found\n",
    "print(\"\\nBest accuracy score:\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Get predictions using the best estimator\n",
    "lr_pred = best_estimator.predict(X)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, lr_pred, target_names=best_estimator.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dines\\OneDrive\\Documents\\GitHub\\441PIFI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Best estimator:\n",
      "SVC(C=10, kernel='linear')\n",
      "\n",
      "Best accuracy score:\n",
      "0.1866689871214758\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        m001       1.00      1.00      1.00         4\n",
      "        m002       1.00      1.00      1.00         4\n",
      "        m003       1.00      1.00      1.00         4\n",
      "        m004       0.80      1.00      0.89         4\n",
      "        m005       1.00      1.00      1.00         4\n",
      "        m006       1.00      1.00      1.00         4\n",
      "        m007       1.00      0.75      0.86         4\n",
      "        m008       1.00      1.00      1.00         4\n",
      "        m009       1.00      1.00      1.00         4\n",
      "        m010       1.00      1.00      1.00         4\n",
      "        m011       1.00      1.00      1.00         4\n",
      "        m012       1.00      1.00      1.00         4\n",
      "        m013       1.00      1.00      1.00         4\n",
      "        m014       1.00      1.00      1.00         4\n",
      "        m015       1.00      1.00      1.00         4\n",
      "        m016       1.00      1.00      1.00         4\n",
      "        m017       1.00      1.00      1.00         4\n",
      "        m018       1.00      1.00      1.00         4\n",
      "        m019       1.00      1.00      1.00         4\n",
      "        m020       1.00      1.00      1.00         4\n",
      "        m021       1.00      1.00      1.00         4\n",
      "        m022       1.00      1.00      1.00         4\n",
      "        m023       1.00      1.00      1.00         4\n",
      "        m024       1.00      1.00      1.00         4\n",
      "        m025       1.00      1.00      1.00         4\n",
      "        m026       1.00      1.00      1.00         4\n",
      "        m027       1.00      1.00      1.00         4\n",
      "        m028       1.00      1.00      1.00         4\n",
      "        m029       1.00      1.00      1.00         4\n",
      "        m030       1.00      1.00      1.00         4\n",
      "        m031       1.00      1.00      1.00         4\n",
      "        m032       1.00      1.00      1.00         4\n",
      "        m033       1.00      1.00      1.00         5\n",
      "        m034       1.00      1.00      1.00         2\n",
      "        m035       1.00      1.00      1.00         4\n",
      "        m036       1.00      1.00      1.00         4\n",
      "        m037       1.00      1.00      1.00         4\n",
      "        m038       1.00      1.00      1.00         4\n",
      "        m039       1.00      1.00      1.00         4\n",
      "        m040       1.00      1.00      1.00         4\n",
      "        m041       1.00      1.00      1.00         4\n",
      "        m042       1.00      1.00      1.00         4\n",
      "        m043       1.00      1.00      1.00         4\n",
      "        m044       1.00      1.00      1.00         4\n",
      "        m045       1.00      1.00      1.00         4\n",
      "        m046       1.00      1.00      1.00         4\n",
      "        m047       1.00      1.00      1.00         4\n",
      "        m048       1.00      1.00      1.00         4\n",
      "        m049       1.00      1.00      1.00         4\n",
      "        m050       1.00      1.00      1.00         4\n",
      "        m051       1.00      1.00      1.00         4\n",
      "        m052       1.00      1.00      1.00         4\n",
      "        m053       1.00      1.00      1.00         4\n",
      "        m054       1.00      1.00      1.00         4\n",
      "        m055       1.00      1.00      1.00         4\n",
      "        m056       1.00      1.00      1.00         4\n",
      "        m057       1.00      1.00      1.00         4\n",
      "        m058       1.00      1.00      1.00         4\n",
      "        m059       1.00      1.00      1.00         4\n",
      "        m060       1.00      1.00      1.00         4\n",
      "        m061       1.00      1.00      1.00         4\n",
      "        m062       1.00      1.00      1.00         4\n",
      "        m063       1.00      1.00      1.00         4\n",
      "        m064       1.00      1.00      1.00         4\n",
      "        m065       1.00      1.00      1.00         4\n",
      "        m066       1.00      1.00      1.00         4\n",
      "        m067       1.00      1.00      1.00         4\n",
      "        m068       1.00      1.00      1.00         4\n",
      "        m069       1.00      1.00      1.00         4\n",
      "        m070       1.00      1.00      1.00         4\n",
      "        m071       1.00      1.00      1.00         4\n",
      "        m072       1.00      1.00      1.00         4\n",
      "        m073       1.00      1.00      1.00         4\n",
      "        m074       1.00      1.00      1.00         4\n",
      "        m075       1.00      1.00      1.00         4\n",
      "        m076       1.00      1.00      1.00         2\n",
      "        w001       1.00      1.00      1.00         4\n",
      "        w002       1.00      1.00      1.00         4\n",
      "        w003       1.00      1.00      1.00         4\n",
      "        w004       1.00      1.00      1.00         4\n",
      "        w005       1.00      1.00      1.00         4\n",
      "        w007       1.00      1.00      1.00         4\n",
      "        w008       1.00      1.00      1.00         4\n",
      "        w009       1.00      1.00      1.00         4\n",
      "        w010       1.00      1.00      1.00         4\n",
      "        w011       1.00      1.00      1.00         4\n",
      "        w012       1.00      1.00      1.00         4\n",
      "        w013       1.00      1.00      1.00         4\n",
      "        w014       1.00      1.00      1.00         4\n",
      "        w015       1.00      1.00      1.00         4\n",
      "        w016       1.00      1.00      1.00         4\n",
      "        w017       1.00      1.00      1.00         4\n",
      "        w018       1.00      1.00      1.00         4\n",
      "        w019       1.00      1.00      1.00         4\n",
      "        w020       1.00      1.00      1.00         4\n",
      "        w021       1.00      1.00      1.00         4\n",
      "        w022       1.00      1.00      1.00         4\n",
      "        w023       1.00      1.00      1.00         4\n",
      "        w024       1.00      1.00      1.00         4\n",
      "        w025       1.00      1.00      1.00         4\n",
      "        w026       1.00      1.00      1.00         4\n",
      "        w027       1.00      1.00      1.00         4\n",
      "        w028       1.00      1.00      1.00         4\n",
      "        w029       1.00      1.00      1.00         4\n",
      "        w030       1.00      1.00      1.00         4\n",
      "        w031       1.00      1.00      1.00         4\n",
      "        w032       1.00      1.00      1.00         4\n",
      "        w033       1.00      1.00      1.00         4\n",
      "        w034       1.00      1.00      1.00         4\n",
      "        w035       1.00      1.00      1.00         4\n",
      "        w036       1.00      1.00      1.00         4\n",
      "        w037       1.00      1.00      1.00         4\n",
      "        w038       1.00      1.00      1.00         4\n",
      "        w039       1.00      1.00      1.00         4\n",
      "        w040       1.00      1.00      1.00         4\n",
      "        w041       1.00      1.00      1.00         4\n",
      "        w042       1.00      1.00      1.00         4\n",
      "        w043       1.00      1.00      1.00         4\n",
      "        w044       1.00      1.00      1.00         4\n",
      "        w045       1.00      1.00      1.00         4\n",
      "        w046       1.00      1.00      1.00         4\n",
      "        w047       1.00      1.00      1.00         2\n",
      "        w048       1.00      1.00      1.00         2\n",
      "        w049       1.00      1.00      1.00         2\n",
      "        w050       1.00      1.00      1.00         2\n",
      "        w051       1.00      1.00      1.00         2\n",
      "        w052       1.00      1.00      1.00         2\n",
      "        w053       1.00      1.00      1.00         2\n",
      "        w054       1.00      1.00      1.00         2\n",
      "        w055       1.00      1.00      1.00         2\n",
      "        w056       1.00      1.00      1.00         2\n",
      "        w057       1.00      1.00      1.00         2\n",
      "        w058       1.00      1.00      1.00         2\n",
      "        w059       1.00      1.00      1.00         2\n",
      "        w060       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       509\n",
      "   macro avg       1.00      1.00      1.00       509\n",
      "weighted avg       1.00      1.00      1.00       509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Create SVC classifier\n",
    "svm_clf = SVC()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print the best estimator found\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"\\nBest estimator:\")\n",
    "print(best_estimator)\n",
    "\n",
    "# Print the best score found\n",
    "print(\"\\nBest accuracy score:\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Get predictions using the best estimator\n",
    "svm_pred = best_estimator.predict(X)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, svm_pred, target_names=best_estimator.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of models\n",
    "models = ['KNN', 'ANN', 'Naive Bayes', 'Logistic Regression', 'SVM']\n",
    "\n",
    "# List of colors for each model\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "# Accuracy scores for each model (you can replace these with your actual accuracy scores)\n",
    "accuracy_scores = [1.0, 1.0, 0.59, 0.71, 1.0]\n",
    "\n",
    "# Creating the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracy_scores, color=colors)\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Displaying the bar graph\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
